{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBt94-0fzzjM"
      },
      "source": [
        "# Section 2. Logistic Regression Spam Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CidQRKLXzskI"
      },
      "source": [
        "> Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "sXAVIOC7vzsb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from tqdm import tqdm\n",
        "from IPython.display import Markdown as md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7eEXHytzvEz"
      },
      "source": [
        "> Reading in the Data\n",
        ">> Randomizing the Data\n",
        "\n",
        ">> Splitting the data into X and Y vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "pcWzY3LQv65C"
      },
      "outputs": [],
      "source": [
        "# Read in the data\n",
        "data = np.genfromtxt('spambase.data', delimiter=',')\n",
        "dataMat = np.array(data)\n",
        "# Set RNG with seed = 0\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(dataMat)\n",
        "# Splitting the data into X and Y vectors\n",
        "X = dataMat[:, :-1]\n",
        "Y =  np.reshape(dataMat[:, -1], (-1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTefGvMH0L8m"
      },
      "source": [
        "> Train-Test Split on the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "QyX0EBgjyEK1"
      },
      "outputs": [],
      "source": [
        "# Split the training and testing sets in a 2:1 ratio\n",
        "trainX, testX, trainY, testY = tts(X, Y, test_size=0.33)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw_UFnfn033A"
      },
      "source": [
        "> Standardizing the Data using the training data\n",
        ">> Take the mean and the standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "Wvd4FvXVzo_P"
      },
      "outputs": [],
      "source": [
        "mean = trainX.mean(axis=0)\n",
        "std = trainX.std(axis=0, ddof=1)\n",
        "####################################################################\n",
        "trainX_std = (trainX - mean) / std\n",
        "bias = np.ones((trainX_std.shape[0], 1))\n",
        "TRAIN_X = np.append(bias, trainX_std , axis=1)\n",
        "\n",
        "####################################################################\n",
        "testX_std = (testX - mean) / std\n",
        "bias = np.ones((testX_std.shape[0], 1))\n",
        "TEST_X = np.append(bias, testX_std , axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Perform Batch Gradient Descent Using the Sigmoid Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc35Ps3h1w1K",
        "outputId": "6d60fae7-b6b6-4a80-d4d3-9ae551c83053"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Logistic Regression Spam Classification: 100%|##########| 1500/1500 [00:02<00:00, 528.55it/s]\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "$$y =-9.2500\\\\ -0.1349x_{1} -0.1705x_{2} +0.2577x_{3} +5.8790x_{4} +1.0009x_{5} +0.4762x_{6} +1.7518x_{7} +0.3820x_{8} +0.4454x_{9} +0.1312x_{10}\\\\ -0.2819x_{11} -0.1539x_{12} -0.0678x_{13} -0.1441x_{14} +0.2585x_{15} +2.3166x_{16} +0.9160x_{17} +0.3563x_{18} +0.7995x_{19} +1.2420x_{20}\\\\ +1.0888x_{21} +0.1253x_{22} +1.5966x_{23} +0.5895x_{24} -7.0444x_{25} -0.7566x_{26} -28.3051x_{27} +0.2577x_{28} -1.9638x_{29} -0.2072x_{30}\\\\ -3.1573x_{31} -0.6525x_{32} -0.5522x_{33} +0.4426x_{34} -6.2377x_{35} +0.6847x_{36} -0.4328x_{37} -0.5104x_{38} -0.7728x_{39} +0.5821x_{40}\\\\ -9.9408x_{41} -2.4063x_{42} -0.4328x_{43} -2.3827x_{44} -2.0925x_{45} -2.3488x_{46} -0.8797x_{47} -2.4694x_{48} -0.4723x_{49} -0.5083x_{50}\\\\ -0.6144x_{51} +0.8888x_{52} +1.4709x_{53} +2.7268x_{54} -1.1341x_{55} +1.9189x_{56} +0.5019x_{57}$$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 264,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "HYPERPARAMETERS = {\n",
        "  \"eta\" : 0.01,\n",
        "  \"term\" : 2 ** (-23),\n",
        "  \"EPSILON\" : 10**(-7),\n",
        "  \"n_iterations\" : 1500,\n",
        "}\n",
        "def sigmoid(x, thetas):\n",
        "      return 1 / (1 + np.exp(-x @ thetas))\n",
        "def dLdtheta(x, y, g):\n",
        "      return x.T @ (g - y)\n",
        "def L(x, y, g):\n",
        "      return -1 / TRAIN_X.shape[0] * y.T @ np.log2(g + HYPERPARAMETERS[\"EPSILON\"]) + \\\n",
        "        (1 - y.T) @ np.log2(1-g + HYPERPARAMETERS[\"EPSILON\"]) \n",
        "\n",
        "thetas = np.random.uniform(-1, 1, (TRAIN_X.shape[1], 1))\n",
        "prev_cost = 0\n",
        "for i in tqdm(range(HYPERPARAMETERS[\"n_iterations\"]), ascii=True, desc=\"Training Logistic Regression Spam Classification\"):\n",
        "  g = sigmoid(TRAIN_X, thetas)\n",
        "  cost = L(TRAIN_X, trainY, g)\n",
        "  gradient = dLdtheta(TRAIN_X, trainY, g)\n",
        "\n",
        "  # update thetas by batch gradient descent\n",
        "  thetas -= HYPERPARAMETERS[\"eta\"] * gradient\n",
        "  if np.abs(prev_cost - cost) < HYPERPARAMETERS[\"term\"]:\n",
        "    i = HYPERPARAMETERS[\"n_iterations\"]\n",
        "  prev_cost = cost\n",
        "\n",
        "\n",
        "\n",
        "res = \"$$y =\"\n",
        "for idx, theta in enumerate(thetas):\n",
        "  # print(f'theta_{idx}: {theta[0]:0.4f}')\n",
        "  if idx != 0:\n",
        "    res += f' {theta[0]:=+0.4f}x_' + '{' + str(idx) + '}'\n",
        "    if idx % 10 == 0:\n",
        "          res += '\\\\\\\\'\n",
        "  else:\n",
        "      res += f'{theta[0]:= 0.4f}\\\\\\\\'\n",
        "res += \"$$\"\n",
        "  \n",
        "md(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "561 123 788 47\n"
          ]
        }
      ],
      "source": [
        "\n",
        "spam_threshold = 0.50\n",
        "\n",
        "yhat = sigmoid(TEST_X , thetas)\n",
        "predictions = np.where(yhat >= spam_threshold, 1, 0)\n",
        "\n",
        "TP = FP = TN = FN = 0\n",
        "for prediction , truth in zip(predictions, testY):\n",
        "    if prediction == truth:\n",
        "        if truth == 1:\n",
        "            TP += 1\n",
        "        else:\n",
        "            TN += 1\n",
        "    else:\n",
        "        if prediction == 1:\n",
        "            FP += 1\n",
        "        else:\n",
        "            FN += 1\n",
        "print(TP, FP , TN , FN)\n",
        "Precision =  TP / (TP + FP) \n",
        "Recall = TP / (TP + FN) \n",
        "F_1 = (2 * Precision * Recall) / (Precision + Recall) \n",
        "Accuracy = (TP + TN) / yhat.shape[0] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "$$Precision = 82.0175\\%,\\hspace{5pt}Recall = 92.2697\\%,\\hspace{5pt}F_1  = 86.8421\\%,\\hspace{5pt}Accuracy = 88.8084\\%$$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 266,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "md(f\"$$Precision = {Precision*100:0.4f}\\%,\" + \"\\\\hspace{5pt}\" +\\\n",
        "     f\"Recall = {Recall*100:0.4f}\\%,\"+ \"\\\\hspace{5pt}\" +\\\n",
        "         f\"F_1  = {F_1*100:0.4f}\\%,\" + \"\\\\hspace{5pt}\" +\\\n",
        "             f\"Accuracy = {Accuracy*100:0.4f}\\%$$\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 3: Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from scipy.stats import norm\n",
        "from IPython.display import Markdown as md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read in the data\n",
        "data = np.genfromtxt('spambase.data', delimiter=',')\n",
        "dataMat = np.array(data)\n",
        "# Set RNG with seed = 0\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(dataMat)\n",
        "# Splitting the data into X and Y vectors\n",
        "X = dataMat[:, :-1]\n",
        "Y =  np.reshape(dataMat[:, -1], (-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the training and testing sets in a 2:1 ratio\n",
        "trainX, testX, trainY, testY = tts(X, Y, test_size=0.33, random_state=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean = trainX.mean(axis=0)\n",
        "std = trainX.std(axis=0, ddof=1)\n",
        "####################################################################\n",
        "trainX_std = (trainX - mean) / std\n",
        "bias = np.ones((trainX_std.shape[0], 1))\n",
        "TRAIN_X = np.append(bias, trainX_std , axis=1)\n",
        "\n",
        "####################################################################\n",
        "testX_std = (testX - mean) / std\n",
        "bias = np.ones((testX_std.shape[0], 1))\n",
        "TEST_X = np.append(bias, testX_std , axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {},
      "outputs": [],
      "source": [
        "spam_mask = np.asarray(np.where(trainY == 1, True, False)).reshape(-1)\n",
        "non_spam_mask = np.invert(spam_mask)\n",
        "\n",
        "spam_train = np.compress(spam_mask, trainX, axis=0)\n",
        "non_spam_train = np.compress(non_spam_mask, trainX, axis=0)\n",
        "\n",
        "spam_train_mean = np.mean(spam_train, axis=0)\n",
        "non_spam_train_mean = np.mean(non_spam_train, axis=0)\n",
        "\n",
        "spam_train_std = np.std(spam_train, axis=0, ddof=1)\n",
        "non_spam_train_std = np.std(non_spam_train, axis=0, ddof=1)\n",
        "\n",
        "spam_prior = spam_mask.shape[0] / trainY.shape[0]\n",
        "non_spam_prior = non_spam_mask.shape[0] / trainY.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "561 337 609 12\n"
          ]
        }
      ],
      "source": [
        "TP = FP = TN = FN = 0\n",
        "# adding the epsilon because there will be divide by zero errors\n",
        "spam_norm = norm.pdf(testX, spam_train_mean, spam_train_std + np.finfo(float).eps) \n",
        "non_spam_norm = norm.pdf(testX, non_spam_train_mean, non_spam_train_std + np.finfo(float).eps) \n",
        "\n",
        "\n",
        "p_spam = np.nan_to_num(np.prod(spam_norm, axis=1) * spam_prior)\n",
        "p_non_spam = np.nan_to_num(np.prod(non_spam_norm, axis=1) * non_spam_prior)\n",
        "\n",
        "predictions = np.asarray(np.where(p_spam >= p_non_spam, 1, 0)).reshape(-1)\n",
        "for prediction , truth in zip(predictions, testY):\n",
        "    if prediction == truth:\n",
        "        if truth == 1:\n",
        "            TP += 1\n",
        "        else:\n",
        "            TN += 1\n",
        "    else:\n",
        "        if prediction == 1:\n",
        "            FP += 1\n",
        "        else:\n",
        "            FN += 1\n",
        "\n",
        "print(TP, FP , TN , FN)\n",
        "Precision =  TP / (TP + FP) \n",
        "Recall = TP / (TP + FN) \n",
        "F_1 = (2 * Precision * Recall) / (Precision + Recall) \n",
        "Accuracy = (TP + TN) / yhat.shape[0] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "$$Precision = 62.4722\\%,\\hspace{5pt}Recall = 97.9058\\%,\\hspace{5pt}F_1  = 76.2746\\%,\\hspace{5pt}Accuracy = 77.0244\\%$$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 273,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "md(f\"$$Precision = {Precision*100:0.4f}\\%,\" + \"\\\\hspace{5pt}\" +\\\n",
        "     f\"Recall = {Recall*100:0.4f}\\%,\"+ \"\\\\hspace{5pt}\" +\\\n",
        "         f\"F_1  = {F_1*100:0.4f}\\%,\" + \"\\\\hspace{5pt}\" +\\\n",
        "             f\"Accuracy = {Accuracy*100:0.4f}\\%$$\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 4: Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from scipy import stats\n",
        "from IPython.display import Markdown as md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read in the data\n",
        "data = np.genfromtxt('spambase.data', delimiter=',')\n",
        "dataMat = np.array(data)\n",
        "# Set RNG with seed = 0\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(dataMat)\n",
        "# Splitting the data into X and Y vectors\n",
        "X = dataMat[:, :-1]\n",
        "Y =  np.reshape(dataMat[:, -1], (-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the training and testing sets in a 2:1 ratio\n",
        "trainX, testX, trainY, testY = tts(X, Y, test_size=0.33)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean = trainX.mean(axis=0)\n",
        "std = trainX.std(axis=0, ddof=1)\n",
        "####################################################################\n",
        "trainX_std = (trainX - mean) / std\n",
        "bias = np.ones((trainX_std.shape[0], 1))\n",
        "TRAIN_X = np.append(bias, trainX_std , axis=1)\n",
        "\n",
        "####################################################################\n",
        "testX_std = (testX - mean) / std\n",
        "bias = np.ones((testX_std.shape[0], 1))\n",
        "TEST_X = np.append(bias, testX_std , axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [],
      "source": [
        "spam_mask = np.asarray(np.where(trainY == 1, True, False)).reshape(-1)\n",
        "non_spam_mask = np.invert(spam_mask)\n",
        "\n",
        "spam_train = np.compress(spam_mask, trainX, axis=0)\n",
        "non_spam_train = np.compress(non_spam_mask, trainX, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [],
      "source": [
        "binary_train_x = (TRAIN_X > TRAIN_X.mean(axis=0)).astype(int)\n",
        "binary_test_x = (TEST_X > TEST_X.mean(axis=0)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, value=None):\n",
        "        self.value = value\n",
        "        self.right = None\n",
        "        self.left = None\n",
        "\n",
        "class DecisionTree():   \n",
        "    def ID3(self, examples, attributes, default):\n",
        "        X = examples[:, :-1]\n",
        "        Y = examples[:, -1]\n",
        "        if len(X) == 0:\n",
        "            return Node(default)\n",
        "        elif ((Y[0] == Y).all()):\n",
        "            return Node(Y[0])\n",
        "        elif (len(attributes) == 1):\n",
        "            return Node(stats.mode(Y).mode[0])\n",
        "        else:\n",
        "            best = self.choose_attribute(attributes, examples)\n",
        "            start = Node(attributes[best])\n",
        "            newAttrs = np.delete(attributes, best)\n",
        "            newExamples = np.delete(examples, best, axis=1)\n",
        "            non_spam = newExamples[(examples[:, best] == 0)]\n",
        "            start.left = self.ID3(non_spam, newAttrs, stats.mode(Y).mode[0])\n",
        "            spam = newExamples[(examples[:, best] == 1)]\n",
        "            start.right = self.ID3(spam, newAttrs, stats.mode(Y).mode[0])\n",
        "        return start\n",
        "    \n",
        "    def choose_attribute(self, attributes, examples):\n",
        "        attributes_entropies = []\n",
        "        eps = np.finfo(float).eps\n",
        "        for i in range(len(attributes)-1):\n",
        "            r0 = examples[(examples[:, i] == 0)]\n",
        "            r1 = examples[(examples[:, i] == 1)]\n",
        "            n0 = r0[(r0[:, -1] == 0)]\n",
        "            p0 = r0[(r0[:, -1] == 1)]\n",
        "            n1 = r1[(r1[:, -1] == 0)]\n",
        "            p1 = r1[(r1[:, -1] == 1)]\n",
        "            h0 = self.H(p0.shape[0], n0.shape[0], r0.shape[0])\n",
        "            h1 = self.H(p1.shape[0], n1.shape[0], r1.shape[0])\n",
        "            entropy = (r0.shape[0]/len(examples) * h0) + (r1.shape[0]/len(examples) * h1)\n",
        "            attributes_entropies.append(entropy)\n",
        "        return np.argmin(attributes_entropies)\n",
        "\n",
        "    def H(self, p, n, num_rows):\n",
        "        pos_p = p/(num_rows+np.finfo(float).eps)\n",
        "        neg_p = n/(num_rows+np.finfo(float).eps)\n",
        "        return - neg_p*np.log2(neg_p + np.finfo(float).eps) \\\n",
        "               - pos_p*np.log2(pos_p + np.finfo(float).eps)\n",
        "\n",
        "    def predict(self, root, testX, testY):\n",
        "        predictions = []\n",
        "        for i in range(testX.shape[0]):\n",
        "            node = root\n",
        "            while True:\n",
        "                if testX[i][node.value] == 0:\n",
        "                    node = node.left\n",
        "                else:\n",
        "                    node = node.right\n",
        "                if node.left is None and node.right is None:\n",
        "                    predictions.append(node.value)\n",
        "                    break\n",
        "        return predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "532 59 852 76\n"
          ]
        }
      ],
      "source": [
        "dt = DecisionTree()\n",
        "root = dt.ID3(np.hstack([binary_train_x, trainY]), np.arange(0, 57), stats.mode(trainY).mode[0])\n",
        "predictions = dt.predict(root, binary_test_x, testY)\n",
        "##################################################################################################\n",
        "TP = FP = TN = FN = 0\n",
        "for prediction , truth in zip(predictions, testY):\n",
        "    if prediction == truth:\n",
        "        if truth == 1:\n",
        "            TP += 1\n",
        "        else:\n",
        "            TN += 1\n",
        "    else:\n",
        "        if prediction == 1:\n",
        "            FP += 1\n",
        "        else:\n",
        "            FN += 1\n",
        "\n",
        "print(TP, FP , TN , FN)\n",
        "Precision =  TP / (TP + FP) \n",
        "Recall = TP / (TP + FN) \n",
        "F_1 = (2 * Precision * Recall) / (Precision + Recall) \n",
        "Accuracy = (TP + TN) / yhat.shape[0] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "$$Precision = 90.0169\\%,\\hspace{5pt}Recall = 87.5000\\%,\\hspace{5pt}F_1  = 88.7406\\%,\\hspace{5pt}Accuracy = 91.1126\\%$$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 282,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "md(f\"$$Precision = {Precision*100:0.4f}\\%,\" + \"\\\\hspace{5pt}\" +\\\n",
        "     f\"Recall = {Recall*100:0.4f}\\%,\"+ \"\\\\hspace{5pt}\" +\\\n",
        "         f\"F_1  = {F_1*100:0.4f}\\%,\" + \"\\\\hspace{5pt}\" +\\\n",
        "             f\"Accuracy = {Accuracy*100:0.4f}\\%$$\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CS383_HW1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "0b75f8f647cd181f09aab730a19140c67cc9b5de80cd4206b264327ba8fec1ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
