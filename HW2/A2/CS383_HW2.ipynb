{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBt94-0fzzjM"
      },
      "source": [
        "# Section 2. Logistic Regression Spam Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CidQRKLXzskI"
      },
      "source": [
        "> Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "sXAVIOC7vzsb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from tqdm import tqdm\n",
        "from IPython.display import Markdown as md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7eEXHytzvEz"
      },
      "source": [
        "> Reading in the Data\n",
        ">> Randomizing the Data\n",
        "\n",
        ">> Splitting the data into X and Y vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "pcWzY3LQv65C"
      },
      "outputs": [],
      "source": [
        "# Read in the data\n",
        "data = np.genfromtxt('spambase.data', delimiter=',')\n",
        "dataMat = np.array(data)\n",
        "# Set RNG with seed = 0\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(dataMat)\n",
        "# Splitting the data into X and Y vectors\n",
        "X = dataMat[:, :-1]\n",
        "Y =  np.reshape(dataMat[:, -1], (-1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTefGvMH0L8m"
      },
      "source": [
        "> Train-Test Split on the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "QyX0EBgjyEK1"
      },
      "outputs": [],
      "source": [
        "# Split the training and testing sets in a 2:1 ratio\n",
        "trainX, testX, trainY, testY = tts(X, Y, test_size=0.333, random_state=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw_UFnfn033A"
      },
      "source": [
        "> Standardizing the Data using the training data\n",
        ">> Take the mean and the standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "Wvd4FvXVzo_P"
      },
      "outputs": [],
      "source": [
        "mean = trainX.mean(axis=0)\n",
        "std = trainX.std(axis=0, ddof=1)\n",
        "####################################################################\n",
        "trainX_std = (trainX - mean) / std\n",
        "bias = np.ones((trainX_std.shape[0], 1))\n",
        "TRAIN_X = np.append(bias, trainX_std , axis=1)\n",
        "\n",
        "####################################################################\n",
        "testX_std = (testX - mean) / std\n",
        "bias = np.ones((testX_std.shape[0], 1))\n",
        "TEST_X = np.append(bias, testX_std , axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Perform Batch Gradient Descent Using the Sigmoid Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc35Ps3h1w1K",
        "outputId": "6d60fae7-b6b6-4a80-d4d3-9ae551c83053"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Logistic Regression Spam Classification: 100%|##########| 1500/1500 [00:06<00:00, 235.55it/s]\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "$$y =-8.7216\\\\ -0.3676x_{1} -0.0427x_{2} -0.2194x_{3} +7.4630x_{4} +0.8732x_{5} +0.7764x_{6} +1.8644x_{7} +0.6760x_{8} +0.4837x_{9} +0.1686x_{10}\\\\ -0.6482x_{11} -0.4498x_{12} -0.1772x_{13} +0.4653x_{14} +1.1342x_{15} +1.3754x_{16} +1.1540x_{17} +0.2235x_{18} -0.6838x_{19} +0.5617x_{20}\\\\ +0.3475x_{21} +0.1549x_{22} +1.5531x_{23} +0.4138x_{24} -3.3752x_{25} -1.2123x_{26} -21.7450x_{27} +0.9069x_{28} -1.5840x_{29} +0.0948x_{30}\\\\ -0.1250x_{31} -3.8789x_{32} -0.4879x_{33} +2.4980x_{34} -2.1108x_{35} +0.8383x_{36} +0.4946x_{37} -0.1948x_{38} -0.2009x_{39} +0.3971x_{40}\\\\ -8.5656x_{41} -3.1524x_{42} -0.1296x_{43} -1.4432x_{44} -1.2485x_{45} -1.7339x_{46} -0.2191x_{47} -0.6023x_{48} -0.1634x_{49} +0.0426x_{50}\\\\ +0.1286x_{51} +1.2250x_{52} +2.9533x_{53} +2.0048x_{54} -0.8513x_{55} +3.3819x_{56} +1.1628x_{57}$$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "HYPERPARAMETERS = {\n",
        "  \"eta\" : 0.01,\n",
        "  \"term\" : 2 ** (-23),\n",
        "  \"EPSILON\" : 10**(-7),\n",
        "  \"n_iterations\" : 1500,\n",
        "}\n",
        "def sigmoid(x, thetas):\n",
        "      return 1 / (1 + np.exp(-x @ thetas))\n",
        "def dLdtheta(x, y, g):\n",
        "      return x.T @ (g - y)\n",
        "def L(x, y, g):\n",
        "      return -1 / TRAIN_X.shape[0] * y.T @ np.log(g + HYPERPARAMETERS[\"EPSILON\"]) + (1 - y.T) @ np.log(1-g + HYPERPARAMETERS[\"EPSILON\"]) \n",
        "\n",
        "thetas = np.random.uniform(-1, 1, (TRAIN_X.shape[1], 1))\n",
        "prev_cost = 0\n",
        "for i in tqdm(range(HYPERPARAMETERS[\"n_iterations\"]), ascii=True, desc=\"Training Logistic Regression Spam Classification\"):\n",
        "  g = sigmoid(TRAIN_X, thetas)\n",
        "  cost = L(TRAIN_X, trainY, g)\n",
        "  gradient = dLdtheta(TRAIN_X, trainY, g)\n",
        "\n",
        "  # update thetas by batch gradient descent\n",
        "  thetas -= HYPERPARAMETERS[\"eta\"] * gradient\n",
        "  if np.abs(prev_cost - cost) < HYPERPARAMETERS[\"term\"]:\n",
        "    i = HYPERPARAMETERS[\"n_iterations\"]\n",
        "  prev_cost = cost\n",
        "\n",
        "\n",
        "\n",
        "res = \"$$y =\"\n",
        "for idx, theta in enumerate(thetas):\n",
        "  # print(f'theta_{idx}: {theta[0]:0.4f}')\n",
        "  if idx != 0:\n",
        "    res += f' {theta[0]:=+0.4f}x_' + '{' + str(idx) + '}'\n",
        "    if idx % 10 == 0:\n",
        "          res += '\\\\\\\\'\n",
        "  else:\n",
        "      res += f'{theta[0]:= 0.4f}\\\\\\\\'\n",
        "res += \"$$\"\n",
        "  \n",
        "md(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "$$Precision = 92.3414\\%,\\hspace{5pt}Recall = 73.2639\\%,\\hspace{5pt}F_1  = 81.7038\\%,\\hspace{5pt}Accuracy = 87.6712\\%$$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "spam_threshold = 0.50\n",
        "\n",
        "yhat = sigmoid(TEST_X , thetas)\n",
        "predictions = np.where(yhat >= spam_threshold, 1, 0)\n",
        "\n",
        "TP = FP = TN = FN = 0\n",
        "for prediction , truth in zip(predictions, testY):\n",
        "    if prediction == truth:\n",
        "        if truth == 1:\n",
        "            TP += 1\n",
        "        else:\n",
        "            TN += 1\n",
        "    else:\n",
        "        if prediction == 1:\n",
        "            FP += 1\n",
        "        else:\n",
        "            FN += 1\n",
        "# print(TP, FP , TN , FN)\n",
        "Precision =  TP / (TP + FP) \n",
        "Recall = TP / (TP + FN) \n",
        "F_1 = (2 * Precision * Recall) / (Precision + Recall) \n",
        "Accuracy = (TP + TN) / yhat.shape[0] \n",
        "# md(\"$$Precision = \\\\frac{TP}{TP + FP},\\\\ Recall = \\\\frac{TP}{TP + FN}, F_1  = \\\\frac{2 \\\\times Precision \\\\times Recall}{Precision + Recall}, Accuracy = \\\\frac{TP + TN}{Y.size}$$\")\n",
        "md(f\"$$Precision = {Precision*100:0.4f}\\%,\" + \"\\\\hspace{5pt}\" + f\"Recall = {Recall*100:0.4f}\\%,\"+ \"\\\\hspace{5pt}\" + f\"F_1  = {F_1*100:0.4f}\\%,\" + \"\\\\hspace{5pt}\" + f\"Accuracy = {Accuracy*100:0.4f}\\%$$\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 3: Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from scipy.stats import norm\n",
        "from IPython.display import Markdown as md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read in the data\n",
        "data = np.genfromtxt('spambase.data', delimiter=',')\n",
        "dataMat = np.array(data)\n",
        "# Set RNG with seed = 0\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(dataMat)\n",
        "# Splitting the data into X and Y vectors\n",
        "X = dataMat[:, :-1]\n",
        "Y =  np.reshape(dataMat[:, -1], (-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the training and testing sets in a 2:1 ratio\n",
        "trainX, testX, trainY, testY = tts(X, Y, test_size=0.33, random_state=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean = trainX.mean(axis=0)\n",
        "std = trainX.std(axis=0, ddof=1)\n",
        "####################################################################\n",
        "trainX_std = (trainX - mean) / std\n",
        "bias = np.ones((trainX_std.shape[0], 1))\n",
        "TRAIN_X = np.append(bias, trainX_std , axis=1)\n",
        "\n",
        "####################################################################\n",
        "testX_std = (testX - mean) / std\n",
        "bias = np.ones((testX_std.shape[0], 1))\n",
        "TEST_X = np.append(bias, testX_std , axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "spam_mask = np.asarray(np.where(trainY == 1, True, False)).reshape(-1)\n",
        "non_spam_mask = np.invert(spam_mask)\n",
        "\n",
        "spam_train = np.compress(spam_mask, trainX, axis=0)\n",
        "non_spam_train = np.compress(non_spam_mask, trainX, axis=0)\n",
        "\n",
        "spam_train_mean = np.mean(spam_train, axis=0)\n",
        "non_spam_train_mean = np.mean(non_spam_train, axis=0)\n",
        "\n",
        "spam_train_std = np.std(spam_train, axis=0, ddof=1)\n",
        "non_spam_train_std = np.std(non_spam_train, axis=0, ddof=1)\n",
        "\n",
        "spam_prior = spam_mask.shape[0] / trainY.shape[0]\n",
        "non_spam_prior = non_spam_mask.shape[0] / trainY.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "561 337 609 12\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "$$Precision = 62.4722\\%,\\hspace{5pt}Recall = 97.9058\\%,\\hspace{5pt}F_1  = 76.2746\\%,\\hspace{5pt}Accuracy = 76.3209\\%$$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TP = FP = TN = FN = 0\n",
        "# adding the epsilon because there will be divide by zero errors\n",
        "spam_norm = norm.pdf(testX, spam_train_mean, spam_train_std + np.finfo(float).eps) \n",
        "non_spam_norm = norm.pdf(testX, non_spam_train_mean, non_spam_train_std + np.finfo(float).eps) \n",
        "\n",
        "\n",
        "p_spam = np.nan_to_num(np.prod(spam_norm, axis=1) * spam_prior)\n",
        "p_non_spam = np.nan_to_num(np.prod(non_spam_norm, axis=1) * non_spam_prior)\n",
        "\n",
        "predictions = np.asarray(np.where(p_spam >= p_non_spam, 1, 0)).reshape(-1)\n",
        "for prediction , truth in zip(predictions, testY):\n",
        "    if prediction == truth:\n",
        "        if truth == 1:\n",
        "            TP += 1\n",
        "        else:\n",
        "            TN += 1\n",
        "    else:\n",
        "        if prediction == 1:\n",
        "            FP += 1\n",
        "        else:\n",
        "            FN += 1\n",
        "\n",
        "print(TP, FP , TN , FN)\n",
        "Precision =  TP / (TP + FP) \n",
        "Recall = TP / (TP + FN) \n",
        "F_1 = (2 * Precision * Recall) / (Precision + Recall) \n",
        "Accuracy = (TP + TN) / yhat.shape[0] \n",
        "# md(\"$$Precision = \\\\frac{TP}{TP + FP},\\\\ Recall = \\\\frac{TP}{TP + FN}, F_1  = \\\\frac{2 \\\\times Precision \\\\times Recall}{Precision + Recall}, Accuracy = \\\\frac{TP + TN}{Y.size}$$\")\n",
        "md(f\"$$Precision = {Precision*100:0.4f}\\%,\" + \"\\\\hspace{5pt}\" + f\"Recall = {Recall*100:0.4f}\\%,\"+ \"\\\\hspace{5pt}\" + f\"F_1  = {F_1*100:0.4f}\\%,\" + \"\\\\hspace{5pt}\" + f\"Accuracy = {Accuracy*100:0.4f}\\%$$\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CS383_HW1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "0b75f8f647cd181f09aab730a19140c67cc9b5de80cd4206b264327ba8fec1ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
